{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as a\n",
    "import prepare as p\n",
    "import wrangle as w\n",
    "import explore as e\n",
    "import model as m\n",
    "import evaluate as eval\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pen.do/support/difference-between-property-and-unit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire data from SQL using my function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "SELECT  parcelid, bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, \n",
    "taxvaluedollarcnt \n",
    "FROM properties_2017\n",
    "JOIN predictions_2017 as pred USING (parcelid)\n",
    "WHERE pred.transactiondate >= '2017-05-01' AND pred.transactiondate <= '2017-08-31'\n",
    "AND (propertylandusetypeid > 259 AND propertylandusetypeid  < 265);\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= a.get_data_from_sql('zillow',sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check my df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- My sql query filter:\n",
    "   - single unit property .\n",
    "   - transaction during  May-August, 2017\n",
    "- calculatedfinishedsquarefee and taxvaluedollarcnt have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use a function that gives us a quick report\n",
    "w.miss_dup_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm going to drop the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.miss_dup_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I'm going to change parcelid to string, it is a uniqure identifier for parcels lots\n",
    "df['parcelid'] = df['parcelid'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bedroomcnt': 'n_bedrooms', \n",
    "                    'bathroomcnt': 'n_bathrooms',\n",
    "                    'calculatedfinishedsquarefeet':'sq_ft',\n",
    "                     'taxvaluedollarcnt': 'assessed_value_usd'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#checking the uniques values for each column\n",
    "columns = df.columns.tolist()\n",
    "print( 'Columns')\n",
    "print(\" \")\n",
    "cat_list = []\n",
    "for col in columns:\n",
    "    print(f'{col} --> {df[col].nunique()} unique values')\n",
    "    if df[col].nunique() < 26:\n",
    "        cat_list.append(col)\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking  the variables that have few values\n",
    "for l in cat_list:\n",
    "    print(l)\n",
    "    print(df[l].value_counts().sort_index())\n",
    "    print(\"--------------------------- \")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Takeaways**\n",
    "- change parcelid to object type\n",
    "- there are property whith 0 bedrooms and bathtooms. I will check this more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore n_bedrooms == 0 & n_bathroos == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.n_bedrooms == 0) & (df.n_bathrooms == 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.n_bedrooms == 0) & (df.n_bathrooms == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I decided to keep the properties with 0 bathrooms and bedrooms it represents a small percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking calculatedfinishedsquarefeet\n",
    "df.sq_ft.sort_values().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.sq_ft <400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaway**\n",
    "- I decided to keep bathrooms and bedrooms = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.cut(df.n_bedrooms,  [0, 2, 4, 12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because all my features are continous i decided to boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.distribution_boxplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways** \n",
    "-  bathrooms , bedrooms, sq_dt and usd_valure are continous.\n",
    "- target is  usd_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = p.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test = p.split_Xy(train,validate,test, 'assessed_value_usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale our data\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = p.scaled_df(X_train, X_validate, X_test, RobustScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- I use Robust Scaler that uses parameters that are more robust to outliers,  because  bathrooms , bedrooms, and sq_dt have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expolore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before Exploration this is what I think:\n",
    "\n",
    "\n",
    "\n",
    "- The variables that can influence the value of home are square feet, and number of bedrooms and at last number of bathrooms. \n",
    "- square feet, and number of bedrooms  can have an influence no matter where the property located.\n",
    "\n",
    "-  other factors can influence the value of a home such as zip code, year built,  school district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I want to explore with my target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "train['assessed_value_usd'].hist(grid=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(train['assessed_value_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.displot( train['assessed_value_usd'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I creating a new df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.concat([X_train_scaled, pd.DataFrame( {'assessed_valure_usd': y_train}) ], axis= 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e.heatmap(train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features in order with more correlation with the target:\n",
    "\n",
    "    - 1. sq_ft\n",
    "    - 2. n_bathrooms\n",
    "    - 3. n_bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_scaled, kind=\"reg\", plot_kws={'line_kws':{'color':'red'}}, corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- sq_ft has more correlation with our target\n",
    "- sq_ft has higher correlation n_bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - T-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Is any diference in  the average of assessed_value_usd  for 2   bedrooms  vs 3 o bedrooms properties?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 𝐻𝑜 : There is no difference in  the average of assessed_value_usd  for the properties with  3  bedrooms  vs 2 bedrooms\n",
    "- 𝐻𝑎 : There is significant  difference in  the average of assessed_value_usd  for the properties with  3  bedrooms  vs 2 bedrooms\n",
    "\n",
    "\n",
    "\n",
    "- **continous** = assessed_value_usd \n",
    "- **categorical** = 2 groups ( bedroom_2, bedroom_3)  \n",
    "- **continous vs categorical** = 2-tailed (significantly different) , 2-sample (comparing 2 groups) t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set Significance Level: $\\alpha = .05$ (in other words Confidence level is 0.95)\n",
    "\n",
    "2. Verify Assumptions:\n",
    "\n",
    "    - Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT)\n",
    "    - Independent samples\n",
    "    - Equal Variances (or set method argument to False when not)\n",
    "3. Compute test statistic and probability (t-statistic & p-value) using stats.ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Significance Level\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my groups\n",
    "bedroom_2 = train_scaled[train_scaled.n_bedrooms == 2].assessed_valure_usd\n",
    "bedroom_3 = train_scaled[train_scaled.n_bedrooms ==3 ].assessed_valure_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Distribution\n",
    "bedroom_2.shape, bedroom_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal Variances (or set method argument to False when not)\n",
    "bedroom_2.var(), bedroom_3.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Test Statistic\n",
    "t, p = stats.ttest_ind(bedroom_2, bedroom_3, equal_var = False)\n",
    "t,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (p < alpha):\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t is negative that means the average in assessed_value_usd is for 3 bedrooms is  greater  than 2 bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average  assessed value  for 2 bedrooms is : $ ',round( bedroom_2.mean(), 2))\n",
    "print('Average  assessed value  for 3 bedrooms is : $', round (bedroom_3.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are bathrooms and bedrooms linearly correlated? \n",
    "- 𝐻𝑜 : There is not a linear correlation between number of bathrooms and number of bedrooms for a property.\n",
    "- 𝐻𝑎 : There is a linear correlation between number of bathrooms and number of bedrooms for a property.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(train_scaled.n_bathrooms, train_scaled.n_bedrooms)\n",
    "r, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (p < alpha):\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.lmplot(x = 'n_bathrooms', y= 'n_bedrooms', data = train_scaled, line_kws={'color': 'red'})\n",
    "plt.xlabel('Bathrooms')\n",
    "plt.ylabel('Bedrooms')\n",
    "plt.title('Bathrooms vs Bedrooms')\n",
    "plt.annotate(f'Pearson r:{r:.4f}\\n p-stat: {p:.2f}', xy =(-3, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- What independent variables are correlated with assessed_value_usd?\n",
    "    - my surprise is bathrooms have higher correlation with our target than bedrooms\n",
    "    - **sq_ft  looks to be the best predictor of our target variable**\n",
    "\n",
    "- Which independent variables are correlated with other independent variables?\n",
    "    - bathrooms and bedrooms are  correlated (if bedrooms increase  also bathrooms tend to increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - SelectkBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =m.select_kbest(X_train_scaled, y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using my function for RFE\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 2,LinearRegression() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot our target\n",
    "sns.displot(y_train,  kind=\"kde\", height =10 ,aspect =1, color = 'red')\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Number of properties\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conver y_train y _ validate to df\n",
    "y_train = pd.DataFrame( {'actual': y_train})\n",
    "y_validate = pd.DataFrame( {'actual': y_validate})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wil check mean and median for y_train. I will choose median, because as you can se in the plot of the target there are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean(), y_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline using mean (I'm using my function to calculate rmse)\n",
    "tra_m = eval.baseline_errors(y_train, 'actual', 'mean')\n",
    "tra_m['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's calculate baseline in validate\n",
    "val_m = eval.baseline_errors(y_validate, 'actual', 'mean')\n",
    "val_m['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline using median\n",
    "tra = eval.baseline_errors(y_train, 'actual', 'median')\n",
    "tra['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using median in validate\n",
    "val = eval.baseline_errors(y_validate, 'actual', 'median')\n",
    "val['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I will select mean for my baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(data = [{\n",
    "    'model': 'mean_baseline',\n",
    "    'rmse_validate': val_m['rmse'],\n",
    "    'r^2_validate' : val_m['r2']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1: LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (X_df_scaled, y_df, actual, method, name):\n",
    "    '''\n",
    "    takes in features scaled df, target df, name of actual target, \n",
    "    type of method and the name of the selected method and \n",
    "    returns a dictionary that contains calculated regression errors.\n",
    "    \n",
    "    X_df_scaled : df that contains scaled featues\n",
    "    y_df: target df\n",
    "    actual: name of the column where is actual value of the target\n",
    "    mehod: type of method to create the model object\n",
    "    name: enter the new name for your model\n",
    "    \n",
    "    Example:\n",
    "    create_model(X_train_scaled[top_sb], y_train, 'actual', LinearRegression(normalize=True), 'modelOLS' )\n",
    "    '''\n",
    "    # fit the thing\n",
    "    method.fit(X_df_scaled, y_df[actual])\n",
    "\n",
    "    # predict train\n",
    "    y_df[name] = method.predict(X_df_scaled)\n",
    "\n",
    "    #calculate regression errors using a created function\n",
    "    train_eval = eval.regression_errors(y_df, actual, name)\n",
    "\n",
    "    return train_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using selected features with selectk best\n",
    "ols_sb = m.create_model(X_train_scaled[top_sb], y_train, 'actual', LinearRegression(normalize=True), 'modelOLS' )\n",
    "ols_sb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using my function for RFE\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 2,LinearRegression(normalize=True) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_rfe = m.create_model(X_train_scaled[top_rfe], y_train, 'actual', LinearRegression(normalize=True), 'modelOLS' )\n",
    "ols_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will calcaulate validate with top_rfe \n",
    "ols_val = create_model(X_validate_scaled[top_rfe], y_validate, 'actual', LinearRegression(normalize=True), 'modelOLS' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train rmse:  ',ols_rfe['rmse'])\n",
    "print('validate rmse', ols_val['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'ols',\n",
    "    'rmse_validate': ols_val['rmse'],\n",
    "    'r^2_validate' : ols_val['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using selected features with selectk best\n",
    "lasso_sb = m.create_model(X_train_scaled[top_sb], y_train, 'actual', LassoLars(alpha=1), 'model_lasso' )\n",
    "lasso_sb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using my function for RFE\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 2,  LassoLars(alpha=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_rfe = m.create_model(X_train_scaled[top_rfe], y_train, 'actual', LassoLars(alpha=1), 'model_lasso' )\n",
    "lasso_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate\n",
    "lasso_val = m.create_model(X_validate_scaled[top_rfe], y_validate, 'actual', LassoLars(alpha=1), 'model_lasso' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train rmse:  ',lasso_rfe['rmse'])\n",
    "print('validate rmse', lasso_val['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'lasso',\n",
    "    'rmse_validate': lasso_val['rmse'],\n",
    "    'r^2_validate' : lasso_val['r2']}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TweedieRegressor (GLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "glm_train = m.create_model(X_train_scaled[top_rfe], y_train, \n",
    "                           'actual', TweedieRegressor(power=1, alpha=0), 'model_glm' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate\n",
    "glm_val = m.create_model(X_validate_scaled[top_rfe], y_validate, \n",
    "                         'actual', TweedieRegressor(power=1, alpha=0), 'model_glm' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train rmse:  ',glm_train['rmse'])\n",
    "print('validate rmse', glm_val['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'glm',\n",
    "    'rmse_validate': glm_val['rmse'],\n",
    "    'r^2_validate' : glm_val['r2']}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 2) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train_scaled)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate_scaled)\n",
    "X_test_degree2 = pf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "pol_reg_train =  m.create_model(X_train_degree2, y_train, \n",
    "                                'actual', LinearRegression(normalize=True), 'model_polreg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate\n",
    "pol_reg_val =  m.create_model(X_validate_degree2, \n",
    "                              y_validate, 'actual',LinearRegression(normalize=True), 'model_polreg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Train rmse:  ',pol_reg_train['rmse'])\n",
    "print('validate rmse', pol_reg_val['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol_reg',\n",
    "    'rmse_validate': pol_reg_val['rmse'],\n",
    "    'r^2_validate' : pol_reg_val['r2']},  ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models= {\n",
    "#     'ols': LinearRegression(normalize=True),\n",
    "#     'lasso': LassoLars(alpha=1),\n",
    "#      'tr':   TweedieRegressor(power=1, alpha=0)}\n",
    "# for k,v in models.items():\n",
    "#     name = 'model_' + k\n",
    "#     met = create_model(X_train_scaled[top_sb], y_train, 'actual', v , name )\n",
    "#     metric_df = metric_df.append(\n",
    "#     {\n",
    "#     'model': name,\n",
    "#     'rmse': met['rmse'],\n",
    "#     'r^2' : met['r2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
